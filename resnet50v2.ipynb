{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "zMzB0bBBRBBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Đường dẫn đến file zip đã tải lên\n",
        "zip_path = \"/content/data.zip\"\n",
        "\n",
        "# Thư mục để giải nén\n",
        "extract_dir = \"data_out\"\n",
        "\n",
        "# Giải nén file zip\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Hiển thị danh sách các file sau khi giải nén\n",
        "print(\"Các file sau khi giải nén:\")\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))\n"
      ],
      "metadata": {
        "id": "LodQewcvSAhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wsHK7JmsQ4CV"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "raw_folder = \"/content/data\"\n",
        "print(\"Danh sách các thư mục con trong 'raw_folder':\", listdir(raw_folder))\n",
        "\n",
        "def save_data(raw_folder=raw_folder):\n",
        "    dest_size = (128, 128)\n",
        "    print(\"Bắt đầu xử lý ảnh...\")\n",
        "\n",
        "    pixels = []\n",
        "    labels = []\n",
        "\n",
        "    # Lặp qua các folder con trong thư mục raw\n",
        "    for folder in listdir(raw_folder):\n",
        "        folder_path = os.path.join(raw_folder, folder)\n",
        "        if os.path.isdir(folder_path) and folder != '.DS_Store':\n",
        "            print(\"Folder=\", folder)\n",
        "            # Lặp qua các file trong từng thư mục chứa các em\n",
        "            for file in listdir(folder_path):\n",
        "                if file != '.DS_Store':\n",
        "                    file_path = os.path.join(folder_path, file)\n",
        "                    print(\"File=\", file)\n",
        "                    pixels.append(cv2.resize(cv2.imread(file_path), dsize=(128,128)))\n",
        "                    labels.append(folder)\n",
        "\n",
        "    pixels = np.array(pixels)\n",
        "    labels = np.array(labels)#.reshape(-1,1)\n",
        "\n",
        "    from sklearn.preprocessing import LabelBinarizer\n",
        "    encoder = LabelBinarizer()\n",
        "    labels = encoder.fit_transform(labels)\n",
        "    print(labels)\n",
        "\n",
        "    file = open('pix.data', 'wb')\n",
        "    # dump information to that file\n",
        "    pickle.dump((pixels,labels), file)\n",
        "    # close the file\n",
        "    file.close()\n",
        "\n",
        "    return\n",
        "\n",
        "def load_data():\n",
        "    file = open('pix.data', 'rb')\n",
        "\n",
        "    # dump information to that file\n",
        "    (pixels, labels) = pickle.load(file)\n",
        "\n",
        "    # close the file\n",
        "    file.close()\n",
        "\n",
        "    print(pixels.shape)\n",
        "    print(labels.shape)\n",
        "\n",
        "    return pixels, labels\n",
        "\n",
        "save_data()\n",
        "X,y = load_data()\n",
        "#random.shuffle(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "def get_model():\n",
        "    model_resnet50v2 = ResNet50V2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "    # Đóng băng các layer\n",
        "    for layer in model_resnet50v2.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Tạo model\n",
        "    input = Input(shape=(128, 128, 3), name='image_input')\n",
        "    output_resnet50v2 = model_resnet50v2(input)\n",
        "\n",
        "    # Thêm các layer FC và Dropout\n",
        "    x = Flatten(name='flatten')(output_resnet50v2)\n",
        "    x = Dense(512, activation='relu', name='fc1')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(512, activation='relu', name='fc2')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(4, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    # Compile\n",
        "    my_model = Model(inputs=input, outputs=x)\n",
        "    my_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return my_model\n",
        "\n",
        "resnet_model = get_model()\n",
        "\n",
        "filepath = \"weights-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.2,\n",
        "                         rescale=1./255,\n",
        "                         width_shift_range=0.2,\n",
        "                         height_shift_range=0.2,\n",
        "                         horizontal_flip=True,\n",
        "                         brightness_range=[0.2, 1.5], fill_mode=\"nearest\")\n",
        "\n",
        "aug_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Fit the model\n",
        "resnet50_hist = resnet_model.fit(aug.flow(X_train, y_train, batch_size=64), epochs=50, validation_data=aug_val.flow(X_test, y_test, batch_size=64), callbacks=callbacks_list)\n",
        "\n",
        "# Save the model\n",
        "resnet_model.save(\"resnet_model.h5\")\n",
        "\n",
        "def plot_model_history(model_history, acc='accuracy', val_acc='val_accuracy'):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    axs[0].plot(range(1, len(model_history.history[acc]) + 1), model_history.history[acc])\n",
        "    axs[0].plot(range(1, len(model_history.history[val_acc]) + 1), model_history.history[val_acc])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1, len(model_history.history[acc]) + 1), len(model_history.history[acc]) / 10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    axs[1].plot(range(1, len(model_history.history['loss']) + 1), model_history.history['loss'])\n",
        "    axs[1].plot(range(1, len(model_history.history['val_loss']) + 1), model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1, len(model_history.history['loss']) + 1), len(model_history.history['loss']) / 10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    #plt.show()\n",
        "    plt.savefig('roc.png')"
      ]
    }
  ]
}